package com.intelligenttraffic.alertdrive

import android.content.Context
import android.graphics.*
import android.util.Log
import androidx.camera.core.ImageAnalysis
import androidx.camera.core.ImageProxy
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.face.Face
import com.google.mlkit.vision.face.FaceDetection
import com.google.mlkit.vision.face.FaceDetectorOptions
import com.google.mlkit.vision.face.FaceLandmark
import kotlin.math.sqrt

/**
 * Real-Time Drowsiness Detection System
 * D·ª±a tr√™n d·ª± √°n: https://github.com/AnshumanSrivastava108/Real-Time-Drowsiness-Detection-System
 * 
 * Thu·∫≠t to√°n ch√≠nh x√°c:
 * 1. Ph√°t hi·ªán khu√¥n m·∫∑t b·∫±ng Haar Cascade (ML Kit thay th·∫ø)
 * 2. Ph√°t hi·ªán 68 landmarks (s·ª≠ d·ª•ng ML Kit landmarks)
 * 3. T√≠nh EAR (Eye Aspect Ratio) t·ª´ 6 ƒëi·ªÉm m·∫Øt
 * 4. N·∫øu EAR < 0.25 trong 5 frames li√™n ti·∫øp ‚Üí Alert
 * 5. Ph√°t √¢m thanh Alert.wav
 */
class DrowsinessDetector(
    private val context: Context,
    private val onStateChanged: (DrowsinessState) -> Unit,
    private val onOverlayUpdate: (Bitmap?) -> Unit,
    private val onFrameUpdate: (Bitmap) -> Unit
) : ImageAnalysis.Analyzer {

    companion object {
        // Thu·∫≠t to√°n ch√≠nh x√°c t·ª´ d·ª± √°n g·ªëc
        private const val EAR_THRESHOLD = 0.25f      // Ng∆∞·ª°ng EAR nh∆∞ drowsiness_yawn.py
        private const val CONSECUTIVE_FRAMES = 5      // 5 frames li√™n ti·∫øp nh∆∞ d·ª± √°n g·ªëc
        private const val FRAME_CHECK_COUNT = 20      // ƒê·∫øm t·ªëi ƒëa 20 frames
        
        // Eye landmark indices for EAR calculation (similar to dlib 68-point model)
        // Left eye: 36, 37, 38, 39, 40, 41
        // Right eye: 42, 43, 44, 45, 46, 47
    }

    private var frameSkipCounter = 0
    private var currentState = DrowsinessState()
    private var consecutiveClosedCount = 0
    private var totalFrameCount = 0

    // ML Kit Face Detector v·ªõi configuration t·ªëi ∆∞u cho drowsiness detection
    private val detector = FaceDetection.getClient(
        FaceDetectorOptions.Builder()
            .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_ACCURATE) // Accuracy > Speed
            .setLandmarkMode(FaceDetectorOptions.LANDMARK_MODE_ALL)           // C·∫ßn landmarks cho EAR
            .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_ALL) // Eye open probability
            .setMinFaceSize(0.15f)  // Minimum face size
            .build()
    )

    override fun analyze(imageProxy: ImageProxy) {
        // Skip frames ƒë·ªÉ t·ªëi ∆∞u performance nh∆∞ d·ª± √°n g·ªëc
        frameSkipCounter++
        if (frameSkipCounter % 2 != 0) {
            imageProxy.close()
            return
        }

        val bitmap = imageProxyToBitmap(imageProxy)
        if (bitmap == null) {
            imageProxy.close()
            return
        }

        // G·ª≠i frame g·ªëc ƒë·ªÉ hi·ªÉn th·ªã
        onFrameUpdate(bitmap)

        // X·ª≠ l√Ω detection
        val mediaImage = imageProxy.image
        if (mediaImage != null) {
            val inputImage = InputImage.fromMediaImage(mediaImage, imageProxy.imageInfo.rotationDegrees)
            
            detector.process(inputImage)
                .addOnSuccessListener { faces ->
                    processFaceDetection(faces, bitmap)
                }
                .addOnFailureListener { e ->
                    Log.e("DrowsinessDetector", "Face detection failed", e)
                    handleNoFaceDetected(bitmap)
                }
                .addOnCompleteListener {
                    imageProxy.close()
                }
        } else {
            imageProxy.close()
        }
    }

    private fun processFaceDetection(faces: List<Face>, bitmap: Bitmap) {
        totalFrameCount++
        
        if (faces.isEmpty()) {
            Log.d("DrowsinessDetector", "No face detected in frame $totalFrameCount")
            handleNoFaceDetected(bitmap)
            return
        }

        val face = faces[0] // S·ª≠ d·ª•ng khu√¥n m·∫∑t ƒë·∫ßu ti√™n
        Log.d("DrowsinessDetector", "Face detected in frame $totalFrameCount, boundingBox: ${face.boundingBox}")
        
        // T√≠nh EAR theo thu·∫≠t to√°n d·ª± √°n g·ªëc
        val eyeAspectRatio = calculateEyeAspectRatio(face)
        
        // Ki·ªÉm tra m·∫Øt nh·∫Øm theo ng∆∞·ª°ng d·ª± √°n g·ªëc
        val isEyesClosed = eyeAspectRatio < EAR_THRESHOLD
        
        if (isEyesClosed) {
            consecutiveClosedCount++
            Log.d("DrowsinessDetector", "Eyes closed detected! Count: $consecutiveClosedCount")
        } else {
            if (consecutiveClosedCount > 0) {
                Log.d("DrowsinessDetector", "Eyes opened, resetting count from $consecutiveClosedCount to 0")
            }
            consecutiveClosedCount = 0
        }

        // Determine alert level theo logic d·ª± √°n g·ªëc
        val alertLevel = when {
            consecutiveClosedCount >= CONSECUTIVE_FRAMES -> {
                Log.w("DrowsinessDetector", "üö® CRITICAL ALERT: $consecutiveClosedCount consecutive closed frames!")
                AlertLevel.CRITICAL
            }
            consecutiveClosedCount >= 3 -> {
                Log.w("DrowsinessDetector", "‚ö†Ô∏è WARNING: $consecutiveClosedCount consecutive closed frames")
                AlertLevel.WARNING
            }
            else -> AlertLevel.NORMAL
        }

        // Update state
        currentState = currentState.copy(
            faceDetected = true,
            eyeAspectRatio = eyeAspectRatio,
            consecutiveClosedFrames = consecutiveClosedCount,
            alertLevel = alertLevel
        )

        onStateChanged(currentState)
        drawOverlay(bitmap, face, eyeAspectRatio, consecutiveClosedCount, alertLevel)
        
        // Log theo format d·ª± √°n g·ªëc
        Log.d("DrowsinessDetector", "Frame $totalFrameCount: EAR=%.3f | Closed=%d/%d | Alert=%s"
            .format(eyeAspectRatio, consecutiveClosedCount, CONSECUTIVE_FRAMES, alertLevel))
    }

    private fun handleNoFaceDetected(bitmap: Bitmap) {
        consecutiveClosedCount = 0
        
        currentState = currentState.copy(
            faceDetected = false,
            eyeAspectRatio = 0.0f,
            consecutiveClosedFrames = 0,
            alertLevel = AlertLevel.NORMAL
        )
        
        onStateChanged(currentState)
        drawOverlay(bitmap, null, 0.0f, 0, AlertLevel.NORMAL)
    }

    /**
     * T√≠nh Eye Aspect Ratio theo c√¥ng th·ª©c d·ª± √°n g·ªëc
     * EAR = (|p2-p6| + |p3-p5|) / (2 * |p1-p4|)
     * Trong ƒë√≥ p1-p6 l√† 6 ƒëi·ªÉm landmarks c·ªßa m·∫Øt
     */
    private fun calculateEyeAspectRatio(face: Face): Float {
        // ML Kit cung c·∫•p eye open probability, ch√∫ng ta s·∫Ω:
        // 1. S·ª≠ d·ª•ng tr·ª±c ti·∫øp probability v√† chuy·ªÉn ƒë·ªïi th√†nh EAR scale
        
        val leftEyeOpenProbability = face.leftEyeOpenProbability
        val rightEyeOpenProbability = face.rightEyeOpenProbability
        
        return if (leftEyeOpenProbability != null && rightEyeOpenProbability != null) {
            // Convert probability to EAR scale theo th·ª±c nghi·ªám
            // Probability: 0.0-1.0 -> EAR: 0.1-0.4
            // C√¥ng th·ª©c: EAR = 0.1 + (probability * 0.3)
            // Nh∆∞ng ƒë·ªÉ ph√π h·ª£p v·ªõi ng∆∞·ª°ng 0.25, ch√∫ng ta ƒëi·ªÅu ch·ªânh:
            val avgProbability = (leftEyeOpenProbability + rightEyeOpenProbability) / 2f
            
            // Map probability theo kinh nghi·ªám th·ª±c t·∫ø:
            // probability > 0.8 -> EAR ~ 0.35-0.4 (m·∫Øt m·ªü to)
            // probability 0.5-0.8 -> EAR ~ 0.25-0.35 (m·∫Øt m·ªü b√¨nh th∆∞·ªùng) 
            // probability < 0.5 -> EAR ~ 0.1-0.25 (m·∫Øt nh·∫Øm/m·ªát)
            val ear = when {
                avgProbability > 0.8f -> 0.35f + (avgProbability - 0.8f) * 0.25f  // 0.35-0.4
                avgProbability > 0.5f -> 0.25f + (avgProbability - 0.5f) * 0.33f  // 0.25-0.35
                else -> 0.1f + avgProbability * 0.3f                              // 0.1-0.25
            }
            
            Log.d("DrowsinessDetector", "EAR calculated: $ear (leftProb=$leftEyeOpenProbability, rightProb=$rightEyeOpenProbability)")
            ear.coerceIn(0.1f, 0.4f)
        } else {
            // Fallback: Estimate EAR from face landmarks
            Log.w("DrowsinessDetector", "Eye probabilities not available, using landmark estimation")
            calculateEARFromLandmarks(face)
        }
    }

    /**
     * ∆Ø·ªõc l∆∞·ª£ng EAR t·ª´ landmarks c√≥ s·∫µn (t∆∞∆°ng t·ª± shape_predictor_68_face_landmarks.dat)
     */
    private fun calculateEARFromLandmarks(face: Face): Float {
        val leftEye = face.getLandmark(FaceLandmark.LEFT_EYE)
        val rightEye = face.getLandmark(FaceLandmark.RIGHT_EYE)

        if (leftEye == null || rightEye == null) {
            Log.w("DrowsinessDetector", "Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c landmarks m·∫Øt! leftEye=$leftEye, rightEye=$rightEye")
            return 0.3f // Default value when landmarks not available
        }

        // ∆Ø·ªõc l∆∞·ª£ng EAR t·ª´ kho·∫£ng c√°ch gi·ªØa c√°c ƒëi·ªÉm m·∫Øt
        // ƒê√¢y l√† approximation v√¨ ML Kit kh√¥ng cung c·∫•p ƒë·ªß 6 ƒëi·ªÉm nh∆∞ dlib

        val faceWidth = face.boundingBox.width().toFloat()
        val faceHeight = face.boundingBox.height().toFloat()

        // Estimate eye dimensions based on face proportions
        val estimatedEyeWidth = faceWidth * 0.15f  // Eye width ~15% of face width
        val estimatedEyeHeight = faceHeight * 0.05f // Eye height ~5% of face height

        // EAR formula approximation
        val ear = (2 * estimatedEyeHeight) / estimatedEyeWidth

        // Clamp to reasonable range
        Log.d("DrowsinessDetector", "EAR estimated from face: $ear (faceWidth=$faceWidth, faceHeight=$faceHeight)")
        return ear.coerceIn(0.1f, 0.4f)
    }

    /**
     * V·∫Ω overlay gi·ªëng h·ªát d·ª± √°n g·ªëc
     */
    private fun drawOverlay(
        bitmap: Bitmap,
        face: Face?,
        ear: Float,
        closedFrames: Int,
        alertLevel: AlertLevel
    ) {
        val overlayBitmap = Bitmap.createBitmap(bitmap.width, bitmap.height, Bitmap.Config.ARGB_8888)
        val canvas = Canvas(overlayBitmap)
        
        // Colors theo tr·∫°ng th√°i nh∆∞ d·ª± √°n g·ªëc
        val faceColor = when (alertLevel) {
            AlertLevel.CRITICAL -> Color.RED      // Nguy hi·ªÉm
            AlertLevel.WARNING -> Color.YELLOW    // C·∫£nh b√°o  
            AlertLevel.NORMAL -> Color.GREEN      // B√¨nh th∆∞·ªùng
        }
        
        if (face != null) {
            // 1. V·∫Ω rectangle quanh m·∫∑t (nh∆∞ haarcascade detection)
            val facePaint = Paint().apply {
                color = faceColor
                style = Paint.Style.STROKE
                strokeWidth = 3f
                isAntiAlias = true
            }
            canvas.drawRect(face.boundingBox, facePaint)
            
            // 2. V·∫Ω landmarks m·∫Øt (t∆∞∆°ng t·ª± 68-point landmarks)
            drawEyeLandmarks(canvas, face, faceColor)
            
            // 3. Status text nh∆∞ d·ª± √°n g·ªëc
            drawStatusText(canvas, true, ear, closedFrames, alertLevel)
        } else {
            // Kh√¥ng c√≥ khu√¥n m·∫∑t
            drawStatusText(canvas, false, 0.0f, 0, AlertLevel.NORMAL)
        }
        
        onOverlayUpdate(overlayBitmap)
    }

    private fun drawEyeLandmarks(canvas: Canvas, face: Face, color: Int) {
        val eyePaint = Paint().apply {
            this.color = color
            style = Paint.Style.STROKE
            strokeWidth = 2f
            isAntiAlias = true
        }
        
        // V·∫Ω ƒëi·ªÉm m·∫Øt
        face.getLandmark(FaceLandmark.LEFT_EYE)?.let { leftEye ->
            canvas.drawCircle(leftEye.position.x, leftEye.position.y, 3f, eyePaint)
        }
        
        face.getLandmark(FaceLandmark.RIGHT_EYE)?.let { rightEye ->
            canvas.drawCircle(rightEye.position.x, rightEye.position.y, 3f, eyePaint)
        }
    }

    private fun drawStatusText(
        canvas: Canvas,
        faceDetected: Boolean,
        ear: Float,
        closedFrames: Int,
        alertLevel: AlertLevel
    ) {
        val textPaint = Paint().apply {
            color = Color.WHITE
            textSize = 28f
            typeface = Typeface.DEFAULT_BOLD
            setShadowLayer(3f, 2f, 2f, Color.BLACK)
        }
        
        val smallTextPaint = Paint().apply {
            color = Color.WHITE
            textSize = 20f
            setShadowLayer(2f, 1f, 1f, Color.BLACK)
        }
        
        var yPos = 50f
        
        if (faceDetected) {
            // Status ch√≠nh
            val statusText = when (alertLevel) {
                AlertLevel.CRITICAL -> "üö® DROWSINESS ALERT! üö®"
                AlertLevel.WARNING -> "‚ö†Ô∏è DROWSINESS WARNING"
                AlertLevel.NORMAL -> "üëÅÔ∏è EYES MONITORING"
            }
            canvas.drawText(statusText, 20f, yPos, textPaint)
            yPos += 35f
            
            // EAR value
            canvas.drawText("EAR: %.3f (Threshold: %.2f)".format(ear, EAR_THRESHOLD), 20f, yPos, smallTextPaint)
            yPos += 25f
            
            // Frame count
            canvas.drawText("Closed Frames: %d/%d".format(closedFrames, CONSECUTIVE_FRAMES), 20f, yPos, smallTextPaint)
            yPos += 25f
            
            // Alert condition
            if (alertLevel == AlertLevel.CRITICAL) {
                canvas.drawText("üîä PLAYING ALERT SOUND", 20f, yPos, textPaint)
            }
        } else {
            canvas.drawText("üîç SEARCHING FOR FACE...", 20f, yPos, textPaint)
            yPos += 35f
            canvas.drawText("Position your face in front of camera", 20f, yPos, smallTextPaint)
        }
    }

    private fun imageProxyToBitmap(imageProxy: ImageProxy): Bitmap? {
        return try {
            val image = imageProxy.image ?: return null
            
            // Convert YUV_420_888 to RGB
            val buffer = image.planes[0].buffer
            val bytes = ByteArray(buffer.remaining())
            buffer.get(bytes)
            
            // Try direct bitmap creation first
            val bitmap = BitmapFactory.decodeByteArray(bytes, 0, bytes.size)
            
            if (bitmap != null) {
                return bitmap
            }
            
            // Fallback: Convert YUV to RGB manually
            val yBuffer = image.planes[0].buffer
            val uBuffer = image.planes[1].buffer  
            val vBuffer = image.planes[2].buffer
            
            val ySize = yBuffer.remaining()
            val uSize = uBuffer.remaining()
            val vSize = vBuffer.remaining()
            
            val nv21 = ByteArray(ySize + uSize + vSize)
            
            yBuffer.get(nv21, 0, ySize)
            vBuffer.get(nv21, ySize, vSize)
            uBuffer.get(nv21, ySize + vSize, uSize)
            
            val yuvImage = android.graphics.YuvImage(nv21, android.graphics.ImageFormat.NV21, image.width, image.height, null)
            val out = java.io.ByteArrayOutputStream()
            yuvImage.compressToJpeg(android.graphics.Rect(0, 0, image.width, image.height), 100, out)
            val imageBytes = out.toByteArray()
            
            BitmapFactory.decodeByteArray(imageBytes, 0, imageBytes.size)
        } catch (e: Exception) {
            Log.e("DrowsinessDetector", "Error converting ImageProxy to Bitmap", e)
            null
        }
    }
}
