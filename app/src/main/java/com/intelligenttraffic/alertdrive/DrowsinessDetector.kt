package com.intelligenttraffic.alertdrive

import android.content.Context
import android.graphics.*
import android.util.Log
import androidx.camera.core.ImageAnalysis
import androidx.camera.core.ImageProxy
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.face.Face
import com.google.mlkit.vision.face.FaceContour
import com.google.mlkit.vision.face.FaceDetection
import com.google.mlkit.vision.face.FaceDetectorOptions
import com.google.mlkit.vision.face.FaceLandmark
import kotlin.math.sqrt

/**
 * Real-Time Drowsiness Detection System
 * D·ª±a tr√™n d·ª± √°n: https://github.com/AnshumanSrivastava108/Real-Time-Drowsiness-Detection-System
 * 
 * Thu·∫≠t to√°n ch√≠nh x√°c:
 * 1. Ph√°t hi·ªán khu√¥n m·∫∑t b·∫±ng Haar Cascade (ML Kit thay th·∫ø)
 * 2. Ph√°t hi·ªán 68 landmarks (s·ª≠ d·ª•ng ML Kit landmarks)
 * 3. T√≠nh EAR (Eye Aspect Ratio) t·ª´ 6 ƒëi·ªÉm m·∫Øt
 * 4. N·∫øu EAR < 0.25 trong 5 frames li√™n ti·∫øp ‚Üí Alert
 * 5. Ph√°t √¢m thanh Alert.wav
 */
class DrowsinessDetector(
    private val context: Context,
    private val onStateChanged: (DrowsinessState) -> Unit,
    private val onOverlayUpdate: (Bitmap?) -> Unit,
    private val onFrameUpdate: (Bitmap) -> Unit
) : ImageAnalysis.Analyzer {

    companion object {
        // Thu·∫≠t to√°n ch√≠nh x√°c d·ª±a tr√™n ML Kit eye open probability
        private const val EAR_THRESHOLD = 0.15f      // Ng∆∞·ª°ng cho eye open probability (< 0.15 = m·∫Øt nh·∫Øm)
        private const val CONSECUTIVE_FRAMES = 8      // TƒÉng l√™n 8 frames ƒë·ªÉ tr√°nh false positive
        private const val FRAME_CHECK_COUNT = 20      // ƒê·∫øm t·ªëi ƒëa 20 frames
        
        // Eye landmark indices for EAR calculation (similar to dlib 68-point model)
        // Left eye: 36, 37, 38, 39, 40, 41
        // Right eye: 42, 43, 44, 45, 46, 47
    }

    private var frameSkipCounter = 0
    private var currentState = DrowsinessState()
    private var consecutiveClosedCount = 0
    private var totalFrameCount = 0

    // Enhanced ML Kit Face Detector v·ªõi contours v√† tracking ƒë·ªÉ c√≥ face box ch√≠nh x√°c
    private val detector = FaceDetection.getClient(
        FaceDetectorOptions.Builder()
            .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_ACCURATE) // Accurate mode cho contours
            .setLandmarkMode(FaceDetectorOptions.LANDMARK_MODE_ALL)        // C·∫ßn landmarks cho EAR
            .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_ALL) // Eye open probability
            .setContourMode(FaceDetectorOptions.CONTOUR_MODE_ALL)          // Enable contours cho face box ch√≠nh x√°c
            .enableTracking()                                              // Enable face tracking
            .setMinFaceSize(0.15f)  // Gi·∫£m min size ƒë·ªÉ detect ƒë∆∞·ª£c face nh·ªè h∆°n
            .build()
    )

    override fun analyze(imageProxy: ImageProxy) {
        // T·ªëi ∆∞u: ch·ªâ x·ª≠ l√Ω m·ªói 4 frames ƒë·ªÉ gi·∫£m lag
        frameSkipCounter++
        if (frameSkipCounter % 4 != 0) {
            imageProxy.close()
            return
        }

        val bitmap = imageProxyToBitmap(imageProxy)
        if (bitmap == null) {
            imageProxy.close()
            return
        }

        onFrameUpdate(bitmap)

        val mediaImage = imageProxy.image
        if (mediaImage != null) {
            val inputImage = InputImage.fromMediaImage(mediaImage, imageProxy.imageInfo.rotationDegrees)
            
            detector.process(inputImage)
                .addOnSuccessListener { faces ->
                    processFaceDetection(faces, bitmap)
                }
                .addOnFailureListener { 
                    handleNoFaceDetected(bitmap)
                }
                .addOnCompleteListener {
                    imageProxy.close()
                }
        } else {
            imageProxy.close()
        }
    }

    private fun processFaceDetection(faces: List<Face>, bitmap: Bitmap) {
        totalFrameCount++
        
        if (faces.isEmpty()) {
            handleNoFaceDetected(bitmap)
            return
        }

        val face = faces[0] // S·ª≠ d·ª•ng khu√¥n m·∫∑t ƒë·∫ßu ti√™n
        
        // T√≠nh EAR t·ª´ 16-point eye contours - ch√≠nh x√°c nh∆∞ documentation
        val eyeAspectRatio = calculateEARFromContours(face)
        
        // Ki·ªÉm tra m·∫Øt nh·∫Øm theo ng∆∞·ª°ng
        val isEyesClosed = eyeAspectRatio < EAR_THRESHOLD
        
        if (isEyesClosed) {
            consecutiveClosedCount++
        } else {
            consecutiveClosedCount = 0
        }

        // Determine alert level v·ªõi logic ch√≠nh x√°c h∆°n
        val alertLevel = when {
            consecutiveClosedCount >= CONSECUTIVE_FRAMES -> AlertLevel.CRITICAL
            consecutiveClosedCount >= (CONSECUTIVE_FRAMES / 2) -> AlertLevel.WARNING
            else -> AlertLevel.NORMAL
        }

        // Update state
        currentState = currentState.copy(
            faceDetected = true,
            eyeAspectRatio = eyeAspectRatio,
            consecutiveClosedFrames = consecutiveClosedCount,
            alertLevel = alertLevel
        )

        onStateChanged(currentState)
        drawAccurateFaceTracking(bitmap, face, eyeAspectRatio, consecutiveClosedCount, alertLevel)
        
        // Log chi ti·∫øt ƒë·ªÉ debug
        if (totalFrameCount % 10 == 0) { // Log m·ªói 10 frames ƒë·ªÉ kh√¥ng spam
            Log.d("DrowsinessDetector", "Frame $totalFrameCount: EAR=%.3f | Threshold=%.3f | Closed=%d/%d | Eyes=%s"
                .format(eyeAspectRatio, EAR_THRESHOLD, consecutiveClosedCount, CONSECUTIVE_FRAMES, 
                if (isEyesClosed) "CLOSED" else "OPEN"))
        }
        
        // Log alert khi c√≥ c·∫£nh b√°o
        if (alertLevel != AlertLevel.NORMAL) {
            Log.w("DrowsinessDetector", "üö® ALERT: EAR=%.3f | Frames=%d/%d | Level=%s"
                .format(eyeAspectRatio, consecutiveClosedCount, CONSECUTIVE_FRAMES, alertLevel))
        }
    }

    private fun handleNoFaceDetected(bitmap: Bitmap) {
        consecutiveClosedCount = 0
        
        currentState = currentState.copy(
            faceDetected = false,
            eyeAspectRatio = 0.0f,
            consecutiveClosedFrames = 0,
            alertLevel = AlertLevel.NORMAL
        )
        
        onStateChanged(currentState)
        drawAccurateFaceTracking(bitmap, null, 0.0f, 0, AlertLevel.NORMAL)
    }

    /**
     * T√≠nh EAR ch√≠nh x√°c t·ª´ ML Kit eye open probability
     * Theo t√†i li·ªáu Google ML Kit Android official
     */
    private fun calculateEARFromContours(face: Face): Float {
        // S·ª≠ d·ª•ng eye open probability t·ª´ ML Kit (ch√≠nh x√°c nh·∫•t)
        val leftEyeOpenProb = face.leftEyeOpenProbability
        val rightEyeOpenProb = face.rightEyeOpenProbability
        
        if (leftEyeOpenProb != null && rightEyeOpenProb != null) {
            // Average c·ªßa 2 m·∫Øt
            val avgEyeOpenProb = (leftEyeOpenProb + rightEyeOpenProb) / 2f
            
            // Convert sang EAR: probability c√†ng cao = m·∫Øt c√†ng m·ªü = EAR c√†ng cao
            // Ng∆∞·ª£c l·∫°i v·ªõi bu·ªìn ng·ªß: EAR th·∫•p = m·∫Øt nh·∫Øm = bu·ªìn ng·ªß
            val ear = avgEyeOpenProb * 0.4f // Scale to 0.0-0.4 range
            
            Log.d("DrowsinessDetector", "Eye Open: Left=%.3f, Right=%.3f, Avg=%.3f, EAR=%.3f"
                .format(leftEyeOpenProb, rightEyeOpenProb, avgEyeOpenProb, ear))
            
            return ear
        }
        
        // Fallback: d√πng contours n·∫øu c√≥
        val leftEyeContour = face.getContour(FaceContour.LEFT_EYE)?.points
        val rightEyeContour = face.getContour(FaceContour.RIGHT_EYE)?.points
        
        if (leftEyeContour != null && rightEyeContour != null && 
            leftEyeContour.size >= 8 && rightEyeContour.size >= 8) {
            
            val leftEAR = calculateEyeAspectRatio(leftEyeContour)
            val rightEAR = calculateEyeAspectRatio(rightEyeContour)
            val avgEAR = (leftEAR + rightEAR) / 2f
            
            Log.d("DrowsinessDetector", "EAR t·ª´ contours: Left=%.3f, Right=%.3f, Avg=%.3f"
                .format(leftEAR, rightEAR, avgEAR))
            
            return avgEAR
        }
        
        // Final fallback
        Log.w("DrowsinessDetector", "Kh√¥ng c√≥ eye data, s·ª≠ d·ª•ng default EAR")
        return 0.3f
    }
    
    /**
     * T√≠nh EAR t·ª´ 16 ƒëi·ªÉm contour c·ªßa m·ªôt m·∫Øt
     * S·ª≠ d·ª•ng c√¥ng th·ª©c EAR chu·∫©n: (|p2-p6| + |p3-p5|) / (2 * |p1-p4|)
     */
    private fun calculateEyeAspectRatio(eyeContour: List<PointF>): Float {
        if (eyeContour.size < 16) return 0.25f
        
        // V·ªõi 16-point contour, ch·ªçn c√°c ƒëi·ªÉm quan tr·ªçng cho EAR
        // ƒêi·ªÉm 0 v√† 8: g√≥c tr√°i v√† ph·∫£i c·ªßa m·∫Øt (horizontal)
        // ƒêi·ªÉm 4 v√† 12: ƒë·ªânh v√† ƒë√°y c·ªßa m·∫Øt (vertical)
        // ƒêi·ªÉm 2,6,10,14: c√°c ƒëi·ªÉm vertical kh√°c
        
        val p1 = eyeContour[0]   // G√≥c tr√°i m·∫Øt
        val p2 = eyeContour[2]   // ƒêi·ªÉm vertical 1
        val p3 = eyeContour[4]   // ƒêi·ªÉm ƒë·ªânh m·∫Øt  
        val p4 = eyeContour[8]   // G√≥c ph·∫£i m·∫Øt
        val p5 = eyeContour[12]  // ƒêi·ªÉm ƒë√°y m·∫Øt
        val p6 = eyeContour[14]  // ƒêi·ªÉm vertical 2
        
        // Kho·∫£ng c√°ch vertical
        val vertical1 = distance(p2, p6)
        val vertical2 = distance(p3, p5)
        
        // Kho·∫£ng c√°ch horizontal  
        val horizontal = distance(p1, p4)
        
        if (horizontal == 0f) return 0.25f
        
        // EAR formula
        val ear = (vertical1 + vertical2) / (2f * horizontal)
        
        return ear.coerceIn(0.1f, 0.5f)
    }
    
    /**
     * T√≠nh kho·∫£ng c√°ch Euclidean gi·ªØa 2 ƒëi·ªÉm
     */
    private fun distance(p1: PointF, p2: PointF): Float {
        val dx = p1.x - p2.x
        val dy = p1.y - p2.y
        return sqrt(dx * dx + dy * dy)
    }

    /**
     * T√≠nh EAR t·ª´ eye open probability (method ch√≠nh x√°c nh·∫•t)
     */
    private fun calculateSimplifiedEAR(face: Face): Float {
        // S·ª≠ d·ª•ng eye open probability t·ª´ ML Kit - ch√≠nh x√°c nh·∫•t
        val leftProb = face.leftEyeOpenProbability
        val rightProb = face.rightEyeOpenProbability
        
        if (leftProb != null && rightProb != null) {
            val avgProb = (leftProb + rightProb) / 2f
            
            // Convert tr·ª±c ti·∫øp: probability -> EAR
            // probability cao = m·∫Øt m·ªü = EAR cao
            // probability th·∫•p = m·∫Øt nh·∫Øm = EAR th·∫•p  
            val ear = avgProb * 0.4f // Scale to 0.0-0.4 range
            
            Log.d("DrowsinessDetector", "Eye open probability: Left=%.3f, Right=%.3f, EAR=%.3f"
                .format(leftProb, rightProb, ear))
            
            return ear
        }
        
        Log.w("DrowsinessDetector", "Kh√¥ng c√≥ eye open probability data")
        return 0.3f // Default khi kh√¥ng c√≥ data
    }

    /**
     * ∆Ø·ªõc l∆∞·ª£ng EAR t·ª´ landmarks c√≥ s·∫µn (t∆∞∆°ng t·ª± shape_predictor_68_face_landmarks.dat)
     */
    private fun calculateEARFromLandmarks(face: Face): Float {
        val leftEye = face.getLandmark(FaceLandmark.LEFT_EYE)
        val rightEye = face.getLandmark(FaceLandmark.RIGHT_EYE)

        if (leftEye == null || rightEye == null) {
            Log.w("DrowsinessDetector", "Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c landmarks m·∫Øt! leftEye=$leftEye, rightEye=$rightEye")
            return 0.3f // Default value when landmarks not available
        }

        // ∆Ø·ªõc l∆∞·ª£ng EAR t·ª´ kho·∫£ng c√°ch gi·ªØa c√°c ƒëi·ªÉm m·∫Øt
        // ƒê√¢y l√† approximation v√¨ ML Kit kh√¥ng cung c·∫•p ƒë·ªß 6 ƒëi·ªÉm nh∆∞ dlib

        val faceWidth = face.boundingBox.width().toFloat()
        val faceHeight = face.boundingBox.height().toFloat()

        // Estimate eye dimensions based on face proportions
        val estimatedEyeWidth = faceWidth * 0.15f  // Eye width ~15% of face width
        val estimatedEyeHeight = faceHeight * 0.05f // Eye height ~5% of face height

        // EAR formula approximation
        val ear = (2 * estimatedEyeHeight) / estimatedEyeWidth

        // Clamp to reasonable range
        Log.d("DrowsinessDetector", "EAR estimated from face: $ear (faceWidth=$faceWidth, faceHeight=$faceHeight)")
        return ear.coerceIn(0.1f, 0.4f)
    }

    /**
     * V·∫Ω h√¨nh vu√¥ng theo d√µi khu√¥n m·∫∑t ch√≠nh x√°c
     */
    private fun drawAccurateFaceTracking(
        bitmap: Bitmap,
        face: Face?,
        ear: Float,
        closedFrames: Int,
        alertLevel: AlertLevel
    ) {
        val overlayBitmap = Bitmap.createBitmap(bitmap.width, bitmap.height, Bitmap.Config.ARGB_8888)
        val canvas = Canvas(overlayBitmap)
        
        if (face != null) {
            // V·∫Ω h√¨nh vu√¥ng theo d√µi khu√¥n m·∫∑t ch√≠nh x√°c
            drawPreciseFaceBox(canvas, face, alertLevel)
            
            // Status text ƒë∆°n gi·∫£n
            drawSimpleStatus(canvas, ear, closedFrames, alertLevel)
        } else {
            drawSimpleStatus(canvas, 0.0f, 0, AlertLevel.NORMAL)
        }
        
        onOverlayUpdate(overlayBitmap)
    }
    
    /**
     * V·∫Ω h√¨nh vu√¥ng theo d√µi khu√¥n m·∫∑t v·ªõi ƒë·ªô ch√≠nh x√°c cao
     */
    private fun drawPreciseFaceBox(canvas: Canvas, face: Face, alertLevel: AlertLevel) {
        val boxColor = when (alertLevel) {
            AlertLevel.CRITICAL -> Color.RED
            AlertLevel.WARNING -> Color.YELLOW    
            AlertLevel.NORMAL -> Color.GREEN
        }
        
        val facePaint = Paint().apply {
            color = boxColor
            style = Paint.Style.STROKE
            strokeWidth = 4f
            isAntiAlias = true
        }
        
        // Ph∆∞∆°ng ph√°p 1: S·ª≠ d·ª•ng face contour ƒë·ªÉ c√≥ bounding box ch√≠nh x√°c nh·∫•t
        val faceOval = face.getContour(FaceContour.FACE)?.points
        
        if (faceOval != null && faceOval.isNotEmpty()) {
            // T√≠nh bounding box ch√≠nh x√°c t·ª´ t·∫•t c·∫£ ƒëi·ªÉm contour c·ªßa khu√¥n m·∫∑t
            var minX = Float.MAX_VALUE
            var minY = Float.MAX_VALUE
            var maxX = Float.MIN_VALUE
            var maxY = Float.MIN_VALUE
            
            for (point in faceOval) {
                minX = minOf(minX, point.x)
                minY = minOf(minY, point.y)
                maxX = maxOf(maxX, point.x)
                maxY = maxOf(maxY, point.y)
            }
            
            // T·∫°o padding ƒë·ªÉ h√¨nh vu√¥ng bao quanh khu√¥n m·∫∑t tho·∫£i m√°i h∆°n
            val padding = 20f
            val preciseRect = RectF(
                minX - padding, 
                minY - padding, 
                maxX + padding, 
                maxY + padding
            )
            
            // V·∫Ω h√¨nh vu√¥ng ch√≠nh x√°c theo d√µi khu√¥n m·∫∑t
            canvas.drawRect(preciseRect, facePaint)
            
            // V·∫Ω cross-hair ·ªü trung t√¢m ƒë·ªÉ tracking t·ªët h∆°n
            val centerX = (minX + maxX) / 2f
            val centerY = (minY + maxY) / 2f
            val crossSize = 10f
            
            val centerPaint = Paint().apply {
                color = boxColor
                strokeWidth = 2f
                isAntiAlias = true
            }
            
            canvas.drawLine(centerX - crossSize, centerY, centerX + crossSize, centerY, centerPaint)
            canvas.drawLine(centerX, centerY - crossSize, centerX, centerY + crossSize, centerPaint)
            
            // Hi·ªÉn th·ªã tracking ID n·∫øu c√≥
            val trackingId = face.trackingId
            if (trackingId != null) {
                val idPaint = Paint().apply {
                    color = boxColor
                    textSize = 16f
                    typeface = Typeface.DEFAULT_BOLD
                    isAntiAlias = true
                }
                canvas.drawText("ID: $trackingId", minX, minY - 5f, idPaint)
            }
            
            Log.d("DrowsinessDetector", "Face tracking: ID=$trackingId center(%.1f,%.1f) t·ª´ ${faceOval.size} contour points"
                .format(centerX, centerY))
                
        } else {
            // Ph∆∞∆°ng ph√°p 2: Fallback v·ªõi bounding box c√≥ s·∫µn nh∆∞ng c·∫£i thi·ªán
            val originalBox = face.boundingBox
            
            // M·ªü r·ªông bounding box m·ªôt ch√∫t ƒë·ªÉ tracking t·ªët h∆°n
            val expandedBox = RectF(
                originalBox.left - 10f,
                originalBox.top - 20f,
                originalBox.right + 10f, 
                originalBox.bottom + 10f
            )
            
            canvas.drawRect(expandedBox, facePaint)
            
            // V·∫Ω cross-hair ·ªü trung t√¢m
            val centerX = expandedBox.centerX()
            val centerY = expandedBox.centerY()
            val crossSize = 10f
            
            val centerPaint = Paint().apply {
                color = boxColor
                strokeWidth = 2f
                isAntiAlias = true
            }
            
            canvas.drawLine(centerX - crossSize, centerY, centerX + crossSize, centerY, centerPaint)
            canvas.drawLine(centerX, centerY - crossSize, centerX, centerY + crossSize, centerPaint)
            
            // Hi·ªÉn th·ªã tracking ID n·∫øu c√≥
            val trackingId = face.trackingId
            if (trackingId != null) {
                val idPaint = Paint().apply {
                    color = boxColor
                    textSize = 16f
                    typeface = Typeface.DEFAULT_BOLD
                    isAntiAlias = true
                }
                canvas.drawText("ID: $trackingId", expandedBox.left, expandedBox.top - 5f, idPaint)
            }
            
            Log.d("DrowsinessDetector", "Face tracking: ID=$trackingId fallback box center(%.1f,%.1f)"
                .format(centerX, centerY))
        }
    }
    
    private fun drawSimpleStatus(canvas: Canvas, ear: Float, closedFrames: Int, alertLevel: AlertLevel) {
        val textPaint = Paint().apply {
            color = Color.WHITE
            textSize = 24f
            typeface = Typeface.DEFAULT_BOLD
            setShadowLayer(2f, 1f, 1f, Color.BLACK)
        }
        
        val statusText = when (alertLevel) {
            AlertLevel.CRITICAL -> "üö® DROWSY!"
            AlertLevel.WARNING -> "‚ö†Ô∏è WARNING" 
            AlertLevel.NORMAL -> "üëÅÔ∏è TRACKING"
        }
        
        canvas.drawText(statusText, 20f, 50f, textPaint)
        canvas.drawText("EAR: %.3f".format(ear), 20f, 80f, textPaint)
        
        if (closedFrames > 0) {
            canvas.drawText("Closed: $closedFrames", 20f, 110f, textPaint)
        }
    }

    private fun imageProxyToBitmap(imageProxy: ImageProxy): Bitmap? {
        return try {
            val image = imageProxy.image ?: return null
            
            // Convert YUV_420_888 to RGB
            val buffer = image.planes[0].buffer
            val bytes = ByteArray(buffer.remaining())
            buffer.get(bytes)
            
            // Try direct bitmap creation first
            val bitmap = BitmapFactory.decodeByteArray(bytes, 0, bytes.size)
            
            if (bitmap != null) {
                return bitmap
            }
            
            // Fallback: Convert YUV to RGB manually
            val yBuffer = image.planes[0].buffer
            val uBuffer = image.planes[1].buffer  
            val vBuffer = image.planes[2].buffer
            
            val ySize = yBuffer.remaining()
            val uSize = uBuffer.remaining()
            val vSize = vBuffer.remaining()
            
            val nv21 = ByteArray(ySize + uSize + vSize)
            
            yBuffer.get(nv21, 0, ySize)
            vBuffer.get(nv21, ySize, vSize)
            uBuffer.get(nv21, ySize + vSize, uSize)
            
            val yuvImage = android.graphics.YuvImage(nv21, android.graphics.ImageFormat.NV21, image.width, image.height, null)
            val out = java.io.ByteArrayOutputStream()
            yuvImage.compressToJpeg(android.graphics.Rect(0, 0, image.width, image.height), 100, out)
            val imageBytes = out.toByteArray()
            
            BitmapFactory.decodeByteArray(imageBytes, 0, imageBytes.size)
        } catch (e: Exception) {
            Log.e("DrowsinessDetector", "Error converting ImageProxy to Bitmap", e)
            null
        }
    }
}
